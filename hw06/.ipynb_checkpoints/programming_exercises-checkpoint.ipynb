{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8270cdb8",
   "metadata": {},
   "source": [
    "**Programming Exercise 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3519a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f69945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchGradientDescentLinearRegressor:\n",
    "    ''' Implementation of Mini-Batch Gradient Descent for Linear Regression '''\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, batch_size=None, epochs=5):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.array([])\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "    \n",
    "    def set_params(self, learning_rate=None, batch_size=None, epochs=None):\n",
    "        if learning_rate:\n",
    "            self.learning_rate = learning_rate\n",
    "            \n",
    "        if batch_size:\n",
    "            self.batch_size = batch_size\n",
    "        \n",
    "        if epochs:\n",
    "            self.epochs = epochs\n",
    "    \n",
    "    def fit(self, X_train, y_train, intercept=0, coef=np.array([])):\n",
    "        if X_train is None:\n",
    "            raise Exception('Training feature data has not bee provided')\n",
    "        \n",
    "        if y_train is None:\n",
    "            raise Exception('Training prediction data has not been provided')\n",
    "            \n",
    "        self.X_train = np.concatenate((np.ones(((X_train.shape[0]), 1)), X_train), axis=1)\n",
    "        self.y_train = y_train\n",
    "        \n",
    "        if intercept:\n",
    "            self.intercept_ = intercept\n",
    "        \n",
    "        if coef.size == X_train.shape[1] - 1:\n",
    "            self.coef_ = coef\n",
    "        else:\n",
    "            self.coef_ = np.zeros(self.X_train.shape[1] - 1)            \n",
    "        \n",
    "        train_set_size = X_train.shape[0]\n",
    "        coeffs = np.append(self.intercept_, self.coef_)\n",
    "        \n",
    "        if self.batch_size is None:\n",
    "            self.batch_size = X_train.shape[0]\n",
    "        \n",
    "        if train_set_size % self.batch_size:\n",
    "            raise Exception('Training set size is not divisible by batch size')\n",
    "        \n",
    "        no_batch_iterations = train_set_size / self.batch_size\n",
    "        J_omegas = np.array([])\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            batches = np.split(np.random.permutation(train_set_size), no_batch_iterations)\n",
    "            \n",
    "            for batch in batches:\n",
    "                X_batch = np.array([self.X_train[train_point_index] for train_point_index in batch])\n",
    "                y_batch = np.array([self.y_train[train_point_index] for train_point_index in batch])\n",
    "                \n",
    "                print('X_batch shape', X_batch.shape)\n",
    "                print('y_batch shape', y_batch.shape)\n",
    "                \n",
    "                y_pred = np.reshape(np.matmul(X_batch, coeffs), y_batch.shape)\n",
    "                print('y_pred shape', y_pred.shape)\n",
    "                \n",
    "                J_omegas = np.append(J_omegas, mean_squared_error(y_batch, y_pred))\n",
    "                \n",
    "                print(y_batch - y_pred)\n",
    "                print(np.matmul(X_batch.T, (y_batch - y_pred)).shape)\n",
    "                \n",
    "                coeffs = coeffs + 2 * self.learning_rate * np.matmul(X_batch.T, (y_batch - y_pred))\n",
    "                \n",
    "        self.intercept_, *self.coef_ = coeffs\n",
    "        \n",
    "        ns = np.linspace(1, J_omegas.shape[0], J_omegas.shape[0]) * self.batch_size\n",
    "    \n",
    "        return J_omegas, ns\n",
    "        \n",
    "    def predict(self, X_eval):\n",
    "        coeffs = np.array([self.intercept_, self.coef_]).flatten()\n",
    "        \n",
    "        X_eval = np.concatenate((np.ones(((X_eval.shape[0]), 1)), X_eval), axis=1)\n",
    "        y_pred = np.matmul(X_eval, coeffs)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f33509",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDLinearRegressor(MiniBatchGradientDescentLinearRegressor):\n",
    "    \n",
    "    def __init__(self, learning_rate, epochs=5):\n",
    "        super().__init__(learning_rate=learning_rate, batch_size=1, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc48fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BGDLinearRegressor(MiniBatchGradientDescentLinearRegressor):\n",
    "    \n",
    "    def __init__(self, learning_rate, epochs=5):\n",
    "        super().__init__(learning_rate=learning_rate, batch_size=None, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22683116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: archive.ics.uci.edu\r\n"
     ]
    }
   ],
   "source": [
    "!curl -o data.xlsx https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183a9019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 200\n",
    "\n",
    "df = pd.read_excel('./data.xlsx')\n",
    "\n",
    "X_train = df.iloc[:N, :8].to_numpy()\n",
    "y_train = df.iloc[:N, 8:9].to_numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b52667b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.90777955, -1.68368888, -0.56026533, ..., -1.34164079,\n",
       "        -1.77951304, -1.33333333],\n",
       "       [ 1.90777955, -1.68368888, -0.56026533, ..., -0.4472136 ,\n",
       "        -1.77951304, -1.33333333],\n",
       "       [ 1.90777955, -1.68368888, -0.56026533, ...,  0.4472136 ,\n",
       "        -1.77951304, -1.33333333],\n",
       "       ...,\n",
       "       [ 1.17682953, -1.14056344,  0.01143399, ..., -0.4472136 ,\n",
       "         0.56195149,  2.        ],\n",
       "       [ 1.17682953, -1.14056344,  0.01143399, ...,  0.4472136 ,\n",
       "         0.56195149,  2.        ],\n",
       "       [ 1.17682953, -1.14056344,  0.01143399, ...,  1.34164079,\n",
       "         0.56195149,  2.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e61d5b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.55 ],\n",
       "       [15.55 ],\n",
       "       [15.55 ],\n",
       "       [15.55 ],\n",
       "       [20.84 ],\n",
       "       [21.46 ],\n",
       "       [20.71 ],\n",
       "       [19.68 ],\n",
       "       [19.5  ],\n",
       "       [19.95 ],\n",
       "       [19.34 ],\n",
       "       [18.31 ],\n",
       "       [17.05 ],\n",
       "       [17.41 ],\n",
       "       [16.95 ],\n",
       "       [15.98 ],\n",
       "       [28.52 ],\n",
       "       [29.9  ],\n",
       "       [29.63 ],\n",
       "       [28.75 ],\n",
       "       [24.77 ],\n",
       "       [23.93 ],\n",
       "       [24.77 ],\n",
       "       [23.93 ],\n",
       "       [ 6.07 ],\n",
       "       [ 6.05 ],\n",
       "       [ 6.01 ],\n",
       "       [ 6.04 ],\n",
       "       [ 6.37 ],\n",
       "       [ 6.4  ],\n",
       "       [ 6.366],\n",
       "       [ 6.4  ],\n",
       "       [ 6.85 ],\n",
       "       [ 6.79 ],\n",
       "       [ 6.77 ],\n",
       "       [ 6.81 ],\n",
       "       [ 7.18 ],\n",
       "       [ 7.1  ],\n",
       "       [ 7.1  ],\n",
       "       [ 7.1  ],\n",
       "       [10.85 ],\n",
       "       [10.54 ],\n",
       "       [10.77 ],\n",
       "       [10.56 ],\n",
       "       [ 8.6  ],\n",
       "       [ 8.49 ],\n",
       "       [ 8.45 ],\n",
       "       [ 8.5  ],\n",
       "       [24.58 ],\n",
       "       [24.63 ],\n",
       "       [24.63 ],\n",
       "       [24.59 ],\n",
       "       [29.03 ],\n",
       "       [29.87 ],\n",
       "       [29.14 ],\n",
       "       [28.09 ],\n",
       "       [26.28 ],\n",
       "       [26.91 ],\n",
       "       [26.37 ],\n",
       "       [25.27 ],\n",
       "       [23.53 ],\n",
       "       [24.03 ],\n",
       "       [23.54 ],\n",
       "       [22.58 ],\n",
       "       [35.56 ],\n",
       "       [37.12 ],\n",
       "       [36.9  ],\n",
       "       [35.94 ],\n",
       "       [32.96 ],\n",
       "       [32.12 ],\n",
       "       [32.94 ],\n",
       "       [32.21 ],\n",
       "       [10.36 ],\n",
       "       [10.43 ],\n",
       "       [10.36 ],\n",
       "       [10.39 ],\n",
       "       [10.71 ],\n",
       "       [10.8  ],\n",
       "       [10.7  ],\n",
       "       [10.75 ],\n",
       "       [11.11 ],\n",
       "       [11.13 ],\n",
       "       [11.09 ],\n",
       "       [11.16 ],\n",
       "       [11.68 ],\n",
       "       [11.69 ],\n",
       "       [11.7  ],\n",
       "       [11.69 ],\n",
       "       [15.41 ],\n",
       "       [15.2  ],\n",
       "       [15.42 ],\n",
       "       [15.21 ],\n",
       "       [12.96 ],\n",
       "       [12.97 ],\n",
       "       [12.93 ],\n",
       "       [13.02 ],\n",
       "       [24.29 ],\n",
       "       [24.31 ],\n",
       "       [24.13 ],\n",
       "       [24.25 ],\n",
       "       [28.88 ],\n",
       "       [29.68 ],\n",
       "       [28.83 ],\n",
       "       [27.9  ],\n",
       "       [26.48 ],\n",
       "       [27.02 ],\n",
       "       [26.33 ],\n",
       "       [25.36 ],\n",
       "       [23.75 ],\n",
       "       [24.23 ],\n",
       "       [23.67 ],\n",
       "       [22.79 ],\n",
       "       [35.65 ],\n",
       "       [37.26 ],\n",
       "       [36.97 ],\n",
       "       [36.03 ],\n",
       "       [33.16 ],\n",
       "       [32.4  ],\n",
       "       [33.12 ],\n",
       "       [32.41 ],\n",
       "       [10.42 ],\n",
       "       [10.46 ],\n",
       "       [10.32 ],\n",
       "       [10.45 ],\n",
       "       [10.64 ],\n",
       "       [10.72 ],\n",
       "       [10.55 ],\n",
       "       [10.68 ],\n",
       "       [11.45 ],\n",
       "       [11.46 ],\n",
       "       [11.32 ],\n",
       "       [11.49 ],\n",
       "       [11.45 ],\n",
       "       [11.42 ],\n",
       "       [11.33 ],\n",
       "       [11.43 ],\n",
       "       [15.41 ],\n",
       "       [15.18 ],\n",
       "       [15.34 ],\n",
       "       [15.19 ],\n",
       "       [12.88 ],\n",
       "       [13.   ],\n",
       "       [12.97 ],\n",
       "       [13.04 ],\n",
       "       [24.28 ],\n",
       "       [24.4  ],\n",
       "       [24.11 ],\n",
       "       [24.35 ],\n",
       "       [28.07 ],\n",
       "       [29.01 ],\n",
       "       [29.62 ],\n",
       "       [29.05 ],\n",
       "       [25.41 ],\n",
       "       [26.47 ],\n",
       "       [26.89 ],\n",
       "       [26.46 ],\n",
       "       [22.93 ],\n",
       "       [23.84 ],\n",
       "       [24.17 ],\n",
       "       [23.87 ],\n",
       "       [35.78 ],\n",
       "       [35.48 ],\n",
       "       [36.97 ],\n",
       "       [36.7  ],\n",
       "       [32.52 ],\n",
       "       [33.28 ],\n",
       "       [32.33 ],\n",
       "       [33.24 ],\n",
       "       [10.39 ],\n",
       "       [10.34 ],\n",
       "       [10.35 ],\n",
       "       [10.38 ],\n",
       "       [10.77 ],\n",
       "       [10.68 ],\n",
       "       [10.68 ],\n",
       "       [10.7  ],\n",
       "       [11.22 ],\n",
       "       [11.16 ],\n",
       "       [11.1  ],\n",
       "       [11.14 ],\n",
       "       [11.59 ],\n",
       "       [11.6  ],\n",
       "       [11.53 ],\n",
       "       [11.61 ],\n",
       "       [15.16 ],\n",
       "       [15.36 ],\n",
       "       [15.12 ],\n",
       "       [15.36 ],\n",
       "       [12.68 ],\n",
       "       [12.63 ],\n",
       "       [12.71 ],\n",
       "       [12.73 ],\n",
       "       [24.38 ],\n",
       "       [24.23 ],\n",
       "       [24.04 ],\n",
       "       [24.32 ],\n",
       "       [29.06 ],\n",
       "       [28.05 ],\n",
       "       [28.86 ],\n",
       "       [29.79 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c80767",
   "metadata": {},
   "source": [
    "Plot magnitude of $J(\\omega)$ during stochastic gradient descent for different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f3cde9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape (1, 9)\n",
      "y_batch shape (1, 1)\n",
      "y_pred shape (1, 1)\n",
      "[[29.63]]\n",
      "(9, 1)\n",
      "X_batch shape (1, 9)\n",
      "y_batch shape (1, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 9 into shape (1,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m SGDLinearRegressor(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.002\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m errors, ns \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(ns, errors, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124meta=0.002$\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mset_params(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mMiniBatchGradientDescentLinearRegressor.fit\u001b[0;34m(self, X_train, y_train, intercept, coef)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_batch shape\u001b[39m\u001b[38;5;124m'\u001b[39m, X_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_batch shape\u001b[39m\u001b[38;5;124m'\u001b[39m, y_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 63\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoeffs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred shape\u001b[39m\u001b[38;5;124m'\u001b[39m, y_pred\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     66\u001b[0m J_omegas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(J_omegas, mean_squared_error(y_batch, y_pred))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/git/Machine_Learning_Homeworks/.venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/Machine_Learning_Homeworks/.venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 9 into shape (1,1)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "model = SGDLinearRegressor(learning_rate=0.002)\n",
    "\n",
    "errors, ns = model.fit(X_train, y_train)\n",
    "plt.plot(ns, errors, label='$\\eta=0.002$')\n",
    "\n",
    "model.set_params(learning_rate=0.005)\n",
    "\n",
    "errors, ns = model.fit(X_train, y_train)\n",
    "plt.plot(ns, errors, label='$\\eta=0.005$')\n",
    "\n",
    "model.set_params(learning_rate=0.01)\n",
    "\n",
    "errors, ns = model.fit(X_train, y_train)\n",
    "plt.plot(ns,errors, label='$\\eta=0.01$')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('$J(\\omega)$')\n",
    "plt.xticks(ticks=[])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "070c94a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape (10, 9)\n",
      "y_batch shape (10, 1)\n",
      "y_pred shape (10, 1)\n",
      "[[37.26]\n",
      " [24.63]\n",
      " [32.96]\n",
      " [26.46]\n",
      " [26.91]\n",
      " [11.09]\n",
      " [10.85]\n",
      " [27.02]\n",
      " [15.12]\n",
      " [11.32]]\n",
      "(9, 1)\n",
      "X_batch shape (10, 9)\n",
      "y_batch shape (10, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 90 into shape (10,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# errors, ns = bgd_model.fit(X_train, y_train)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# plt.plot(ns, errors, label=\"$\\eta=0.01$, batch GD\")\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# errors, ns = sgd_model.fit(X_train, y_train, 0.01)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# plt.plot(ns,errors, label=\"$\\eta=0.01$, stochastic GD\")\u001b[39;00m\n\u001b[1;32m     13\u001b[0m mbgd_model \u001b[38;5;241m=\u001b[39m MiniBatchGradientDescentLinearRegressor(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m errors, ns \u001b[38;5;241m=\u001b[39m \u001b[43mmbgd_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(ns,errors, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124meta=0.01$, mini-batch GD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mMiniBatchGradientDescentLinearRegressor.fit\u001b[0;34m(self, X_train, y_train, intercept, coef)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_batch shape\u001b[39m\u001b[38;5;124m'\u001b[39m, X_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_batch shape\u001b[39m\u001b[38;5;124m'\u001b[39m, y_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 63\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoeffs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred shape\u001b[39m\u001b[38;5;124m'\u001b[39m, y_pred\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     66\u001b[0m J_omegas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(J_omegas, mean_squared_error(y_batch, y_pred))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/git/Machine_Learning_Homeworks/.venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/Machine_Learning_Homeworks/.venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 90 into shape (10,1)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "bgd_model = BGDLinearRegressor(learning_rate=0.01)\n",
    "\n",
    "# errors, ns = bgd_model.fit(X_train, y_train)\n",
    "# plt.plot(ns, errors, label=\"$\\eta=0.01$, batch GD\")\n",
    "\n",
    "# sgd_model = SGDLinearRegressor(learning_rate=0.01)\n",
    "\n",
    "# errors, ns = sgd_model.fit(X_train, y_train, 0.01)\n",
    "# plt.plot(ns,errors, label=\"$\\eta=0.01$, stochastic GD\")\n",
    "\n",
    "mbgd_model = MiniBatchGradientDescentLinearRegressor(batch_size=10, learning_rate=0.01)\n",
    "\n",
    "errors, ns = mbgd_model.fit(X_train, y_train)\n",
    "plt.plot(ns,errors, label=\"$\\eta=0.01$, mini-batch GD\")\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"$J(\\omega)$\")\n",
    "plt.xticks(ticks=[])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f18cb9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape (1, 6)\n",
      "y_batch shape (1,)\n",
      "y_pred shape (1,)\n",
      "[2.]\n",
      "(6,)\n",
      "X_batch shape (1, 6)\n",
      "y_batch shape (1,)\n",
      "y_pred shape (1,)\n",
      "[-7.4]\n",
      "(6,)\n",
      "X_batch shape (1, 6)\n",
      "y_batch shape (1,)\n",
      "y_pred shape (1,)\n",
      "[-87.24]\n",
      "(6,)\n",
      "X_batch shape (1, 6)\n",
      "y_batch shape (1,)\n",
      "y_pred shape (1,)\n",
      "[7114.568]\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "model = SGDLinearRegressor(learning_rate=0.1, epochs=1)\n",
    "\n",
    "X_train = np.array([\n",
    "    [4, 1, 4, 16, 1],\n",
    "    [2, 8, 16, 4, 64],\n",
    "    [1, 0, 0, 1, 0],\n",
    "    [3, 2, 6, 9, 4]\n",
    "])\n",
    "\n",
    "y_train = np.array([2, -14, 1, -1])\n",
    "\n",
    "errors, ns = model.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
