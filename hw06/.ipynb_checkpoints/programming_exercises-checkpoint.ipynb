{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8270cdb8",
   "metadata": {},
   "source": [
    "**Programming Exercise 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3519a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f69945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchGradientDescentLinearRegressor:\n",
    "    ''' Implementation of Mini-Batch Gradient Descent for Linear Regression '''\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, batch_size=None, epochs=5):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.array([])\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "    \n",
    "    def set_params(self, learning_rate=None, batch_size=None, epochs=None):\n",
    "        if learning_rate:\n",
    "            self.learning_rate = learning_rate\n",
    "            \n",
    "        if batch_size:\n",
    "            self.batch_size = batch_size\n",
    "        \n",
    "        if epochs:\n",
    "            self.epochs = epochs\n",
    "    \n",
    "    def fit(self, X_train, y_train, intercept=0, coef=np.array([])):\n",
    "        if X_train is None:\n",
    "            raise Exception('Training feature data has not bee provided')\n",
    "        \n",
    "        if y_train is None:\n",
    "            raise Exception('Training prediction data has not been provided')\n",
    "            \n",
    "        self.X_train = np.concatenate((np.ones(((X_train.shape[0]), 1)), X_train), axis=1)\n",
    "        self.y_train = y_train\n",
    "        \n",
    "        if intercept:\n",
    "            self.intercept_ = intercept\n",
    "        \n",
    "        if coef.size == X_train.shape[1] - 1:\n",
    "            self.coef_ = coef\n",
    "        else:\n",
    "            self.coef_ = np.zeros(self.X_train.shape[1] - 1)            \n",
    "        \n",
    "        train_set_size = X_train.shape[0]\n",
    "        coeffs = np.append(self.intercept_, self.coef_)\n",
    "        \n",
    "        if train_set_size % self.batch_size:\n",
    "            raise Exception('Training set size is not divisible by batch size')\n",
    "        \n",
    "        no_batch_iterations = train_set_size / self.batch_size\n",
    "        J_omegas = np.array([])\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "#             batches = np.split(np.random.permutation(train_set_size), no_batch_iterations)\n",
    "            batches = np.split(range(train_set_size), no_batches_iterations)\n",
    "    \n",
    "            print(batches)\n",
    "            \n",
    "            for batch in batches:\n",
    "                X_batch = np.array([self.X_train[train_point_index] for train_point_index in batch])\n",
    "                y_batch = np.array([self.y_train[train_point_index] for train_point_index in batch])\n",
    "                \n",
    "                y_pred = np.matmul(X_batch, coeffs)\n",
    "                \n",
    "                print(batch)\n",
    "                print(y_batch, y_pred)\n",
    "                \n",
    "                J_omegas = np.append(J_omegas, mean_squared_error(y_batch, y_pred))\n",
    "                \n",
    "                coeffs = coeffs + 2 * self.learning_rate * np.matmul(X_batch.T, (y_batch - y_pred)).flatten()\n",
    "                \n",
    "        self.intercept_, *self.coef_ = coeffs\n",
    "        \n",
    "        ns = np.linspace(1, J_omegas.shape[0], J_omegas.shape[0]) * no_batch_iterations\n",
    "    \n",
    "        return J_omegas, ns\n",
    "        \n",
    "    def predict(self, X_eval):\n",
    "        coeffs = np.array([self.intercept_, self.coef_]).flatten()\n",
    "        \n",
    "        X_eval = np.concatenate((np.ones(((X_eval.shape[0]), 1)), X_eval), axis=1)\n",
    "        y_pred = np.matmul(X_eval, coeffs)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f33509",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDLinearRegressor(MiniBatchGradientDescentLinearRegressor):\n",
    "    \n",
    "    def __init__(self, learning_rate, epochs=5):\n",
    "        super().__init__(learning_rate=learning_rate, batch_size=1, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cc48fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BGDLinearRegressor(MiniBatchGradientDescentLinearRegressor):\n",
    "    \n",
    "    def __init__(self, learning_rate, epochs=5):\n",
    "        super().__init__(learning_rate=learning_rate, batch_size=None, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22683116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 62 76189   62 47616    0     0  25950      0  0:00:02  0:00:01  0:00:01 25962\n",
      "100 76189  100 76189    0     0  37513      0  0:00:02  0:00:02 --:--:-- 37550\n"
     ]
    }
   ],
   "source": [
    "!curl -o data.xlsx https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "183a9019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1    0\n",
      "X2    0\n",
      "X3    0\n",
      "X4    0\n",
      "X5    0\n",
      "X6    0\n",
      "X7    0\n",
      "X8    0\n",
      "dtype: int64\n",
      "Y1    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "N = 200\n",
    "\n",
    "df = pd.read_excel('./data.xlsx')\n",
    "\n",
    "X_train = df.iloc[:N, :8].to_numpy()\n",
    "y_train = df.iloc[:N, 8:9].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c80767",
   "metadata": {},
   "source": [
    "Plot magnitude of $J(\\omega)$ during stochastic gradient descent for different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85f3cde9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[113]\n",
      "[[37.26]] [0.]\n",
      "[50]\n",
      "[[24.63]] [66300.44909717]\n",
      "[68]\n",
      "[[32.96]] [-1.26197315e+08]\n",
      "[155]\n",
      "[[26.46]] [2.67170631e+11]\n",
      "[57]\n",
      "[[26.91]] [-4.84762678e+14]\n",
      "[82]\n",
      "[[11.09]] [1.06796136e+18]\n",
      "[40]\n",
      "[[10.85]] [-3.09902881e+21]\n",
      "[105]\n",
      "[[27.02]] [7.36440459e+24]\n",
      "[186]\n",
      "[[15.12]] [-1.74967364e+28]\n",
      "[130]\n",
      "[[11.32]] [5.07759582e+31]\n",
      "[54]\n",
      "[[29.14]] [-1.08593068e+35]\n",
      "[177]\n",
      "[[11.16]] [2.32192932e+38]\n",
      "[98]\n",
      "[[24.13]] [-4.53948498e+41]\n",
      "[172]\n",
      "[[10.77]] [8.51249998e+44]\n",
      "[62]\n",
      "[[23.54]] [-1.88378589e+48]\n",
      "[149]\n",
      "[[29.01]] [3.49952722e+51]\n",
      "[146]\n",
      "[[24.11]] [-5.55596951e+54]\n",
      "[74]\n",
      "[[10.36]] [9.97902946e+57]\n",
      "[135]\n",
      "[[11.43]] [-2.58425901e+61]\n",
      "[164]\n",
      "[[32.52]] [6.84200959e+64]\n",
      "[187]\n",
      "[[15.36]] [-1.88359784e+68]\n",
      "[153]\n",
      "[[26.47]] [4.4762219e+71]\n",
      "[59]\n",
      "[[25.27]] [-8.12179574e+74]\n",
      "[87]\n",
      "[[11.69]] [1.85948554e+78]\n",
      "[48]\n",
      "[[24.58]] [-3.78273012e+81]\n",
      "[37]\n",
      "[[7.1]] [7.69236033e+84]\n",
      "[38]\n",
      "[[7.1]] [-2.23594895e+88]\n",
      "[127]\n",
      "[[10.68]] [6.02706866e+91]\n",
      "[132]\n",
      "[[11.45]] [-1.62450931e+95]\n",
      "[65]\n",
      "[[37.12]] [4.0630951e+98]\n",
      "[123]\n",
      "[[10.45]] [-8.9910561e+101]\n",
      "[100]\n",
      "[[28.88]] [1.76737292e+105]\n",
      "[77]\n",
      "[[10.8]] [-3.62623734e+108]\n",
      "[76]\n",
      "[[10.71]] [9.07765444e+111]\n",
      "[163]\n",
      "[[36.7]] [-2.0960267e+115]\n",
      "[47]\n",
      "[[8.5]] [5.64433891e+118]\n",
      "[52]\n",
      "[[29.03]] [-1.35352447e+122]\n",
      "[99]\n",
      "[[24.25]] [2.14885359e+125]\n",
      "[109]\n",
      "[[24.23]] [-3.65093927e+128]\n",
      "[6]\n",
      "[[20.71]] [6.78231562e+131]\n",
      "[1]\n",
      "[[15.55]] [-1.07675927e+135]\n",
      "[23]\n",
      "[[23.93]] [2.0503067e+138]\n",
      "[78]\n",
      "[[10.7]] [-4.99498657e+141]\n",
      "[115]\n",
      "[[36.03]] [1.15334168e+145]\n",
      "[150]\n",
      "[[29.62]] [-2.24235932e+148]\n",
      "[122]\n",
      "[[10.32]] [4.40729787e+151]\n",
      "[106]\n",
      "[[26.33]] [-8.94914801e+154]\n",
      "[147]\n",
      "[[24.35]] [1.44984936e+158]\n",
      "[161]\n",
      "[[35.48]] [-2.57814175e+161]\n",
      "[107]\n",
      "[[25.36]] [5.12380871e+164]\n",
      "[190]\n",
      "[[12.71]] [-1.26162476e+168]\n",
      "[10]\n",
      "[[19.34]] [3.10720168e+171]\n",
      "[26]\n",
      "[[6.01]] [-6.30851689e+174]\n",
      "[45]\n",
      "[[8.49]] [1.74874933e+178]\n",
      "[128]\n",
      "[[11.45]] [-5.25119417e+181]\n",
      "[118]\n",
      "[[33.12]] [1.33477955e+185]\n",
      "[4]\n",
      "[[20.84]] [-2.77775684e+188]\n",
      "[191]\n",
      "[[12.73]] [6.65930979e+191]\n",
      "[180]\n",
      "[[11.59]] [-2.07644055e+195]\n",
      "[60]\n",
      "[[23.53]] [4.97412041e+198]\n",
      "[15]\n",
      "[[15.98]] [-9.9088094e+201]\n",
      "[143]\n",
      "[[13.04]] [2.554079e+205]\n",
      "[94]\n",
      "[[12.93]] [-8.55242952e+208]\n",
      "[5]\n",
      "[[21.46]] [2.05090261e+212]\n",
      "[79]\n",
      "[[10.75]] [-4.20807349e+215]\n",
      "[160]\n",
      "[[35.78]] [9.71631912e+218]\n",
      "[7]\n",
      "[[19.68]] [-1.88901183e+222]\n",
      "[141]\n",
      "[[13.]] [4.52867568e+225]\n",
      "[20]\n",
      "[[24.77]] [-1.29468089e+229]\n",
      "[158]\n",
      "[[24.17]] [2.87763375e+232]\n",
      "[14]\n",
      "[[16.95]] [-5.73252466e+235]\n",
      "[42]\n",
      "[[10.77]] [1.4253097e+239]\n",
      "[166]\n",
      "[[32.33]] [-3.92419271e+242]\n",
      "[139]\n",
      "[[15.19]] [1.08033839e+246]\n",
      "[90]\n",
      "[[15.42]] [-3.37372792e+249]\n",
      "[124]\n",
      "[[10.64]] [9.41797718e+252]\n",
      "[64]\n",
      "[[35.56]] [-2.17457318e+256]\n",
      "[55]\n",
      "[[28.09]] [4.22773579e+259]\n",
      "[95]\n",
      "[[13.02]] [-1.01356676e+263]\n",
      "[13]\n",
      "[[17.41]] [2.61303919e+266]\n",
      "[145]\n",
      "[[24.4]] [-4.44032872e+269]\n",
      "[72]\n",
      "[[10.36]] [7.97501226e+272]\n",
      "[19]\n",
      "[[28.75]] [-1.76477155e+276]\n",
      "[192]\n",
      "[[24.38]] [3.13877374e+279]\n",
      "[56]\n",
      "[[26.28]] [-5.0841638e+282]\n",
      "[8]\n",
      "[[19.5]] [9.22457954e+285]\n",
      "[179]\n",
      "[[11.14]] [-2.03221928e+289]\n",
      "[162]\n",
      "[[36.97]] [4.88773167e+292]\n",
      "[110]\n",
      "[[23.67]] [-1.01831028e+296]\n",
      "[198]\n",
      "[[28.86]] [1.89175553e+299]\n",
      "[140]\n",
      "[[12.88]] [-4.53525653e+302]\n",
      "[16]\n",
      "[[28.52]] [1.2214494e+306]\n",
      "[63]\n",
      "[[22.58]] [-inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Enis Mustafaj\\AppData\\Local\\Temp\\ipykernel_19388\\2605479784.py:64: RuntimeWarning: overflow encountered in matmul\n",
      "  coeffs = coeffs + 2 * self.learning_rate * np.matmul(X_batch.T, (y_batch - y_pred)).flatten()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m SGDLinearRegressor(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.002\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m errors, ns \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(ns, errors, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124meta=0.002$\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mset_params(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m)\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mMiniBatchGradientDescentLinearRegressor.fit\u001b[1;34m(self, X_train, y_train, intercept, coef)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;28mprint\u001b[39m(batch)\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;28mprint\u001b[39m(y_batch, y_pred)\n\u001b[1;32m---> 62\u001b[0m         J_omegas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(J_omegas, \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     64\u001b[0m         coeffs \u001b[38;5;241m=\u001b[39m coeffs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(X_batch\u001b[38;5;241m.\u001b[39mT, (y_batch \u001b[38;5;241m-\u001b[39m y_pred))\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_ \u001b[38;5;241m=\u001b[39m coeffs\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:438\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_squared_error\u001b[39m(\n\u001b[0;32m    379\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    380\u001b[0m ):\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \n\u001b[0;32m    383\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m    0.825...\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 438\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    442\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_regression.py:96\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m     95\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m---> 96\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     99\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    796\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    797\u001b[0m         )\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 800\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    108\u001b[0m         allow_nan\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m    112\u001b[0m     ):\n\u001b[0;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    117\u001b[0m             )\n\u001b[0;32m    118\u001b[0m         )\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "model = SGDLinearRegressor(learning_rate=0.002)\n",
    "\n",
    "errors, ns = model.fit(X_train, y_train)\n",
    "plt.plot(ns, errors, label='$\\eta=0.002$')\n",
    "\n",
    "model.set_params(learning_rate=0.005)\n",
    "\n",
    "errors, ns = model.fit(X_train, y_train)\n",
    "plt.plot(ns, errors, label='$\\eta=0.005$')\n",
    "\n",
    "model.set_params(learning_rate=0.01)\n",
    "\n",
    "errors, ns = stochastic_gradient(X_train, y_train)\n",
    "plt.plot(ns,errors, label='$\\eta=0.01$')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('$J(\\omega)$')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "529c58c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[-14] [0.]\n",
      "[2]\n",
      "[1] [-19.6]\n",
      "[0]\n",
      "[2] [-498.68]\n",
      "[3]\n",
      "[-1] [17628.192]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.96000000e+02, 4.24360000e+02, 2.50680462e+05, 3.10788411e+08]),\n",
       " array([ 4.,  8., 12., 16.]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDLinearRegressor(learning_rate=0.1, epochs=1)\n",
    "\n",
    "X_train = np.array([\n",
    "    [4, 1, 4, 16, 1],\n",
    "    [2, 8, 16, 4, 64],\n",
    "    [1, 0, 0, 1, 0],\n",
    "    [3, 2, 6, 9, 4]\n",
    "])\n",
    "\n",
    "y_train = np.array([2, -14, 1, -1])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc501530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
